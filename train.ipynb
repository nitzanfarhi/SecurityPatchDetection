{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.63.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
      "Requirement already up-to-date: scipy in /usr/local/lib/python3.8/dist-packages (1.8.0)\n",
      "Requirement already up-to-date: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.22.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install -U scikit-learn scipy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9fda54-c18e-4e94-aa6b-1b5b7b25695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import random\n",
    "import pylab\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from numpy import array\n",
    "from tensorflow.keras.layers import Dense, LSTM,GRU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import Sequential\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "from enum import Enum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6cb407-c302-4cff-96c3-72e9f1c9dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\n",
    "        seq_x = np.pad(seq_x, ((0, 0), (0, 30 - seq_x.shape[1])), 'constant')\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y[-1])\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6867b302-c4c2-4ef1-98a8-b351db5e8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def draw_timeline(name,vulns,first_date, last_date):\n",
    "\n",
    "    dates = vulns\n",
    "    dates += [first_date]\n",
    "    dates += [last_date]\n",
    "\n",
    "    values = [1]*len(dates)\n",
    "    values[-1] = 2\n",
    "    values[-2] = 2\n",
    "\n",
    "    X = pd.to_datetime(dates)\n",
    "    fig, ax = plt.subplots(figsize=(6,1))\n",
    "    ax.scatter(X, [1]*len(X), c=values,\n",
    "               marker='s', s=100)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    # everything after this is turning off stuff that's plotted by default\n",
    "    ax.set_title(name)\n",
    "    ax.yaxis.set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    ax.get_yaxis().set_ticklabels([])\n",
    "    # day = pd.to_timedelta(\"1\", unit='D')\n",
    "    # plt.xlim(X[0] - day, X[-1] + day)\n",
    "    plt.show()\n",
    "    #plt.subplots_adjust(bottom=0.15)\n",
    "    #plt.savefig(f\"D:/cve/images/timeline/{name}.jpg\", transparent=False)\n",
    "    \n",
    "    \n",
    "def find_benign_events(cur_repo_data,gap_days, num_of_events):\n",
    "    benign_events = []\n",
    "    retries = num_of_events * 5\n",
    "    counter = 0\n",
    "    for _ in range(num_of_events):\n",
    "        found_event = False\n",
    "        while not found_event:\n",
    "            if counter >=retries:\n",
    "                return benign_events\n",
    "            try:\n",
    "                cur_event = random.randint(2*gap_days+1,cur_repo_data.shape[0]-gap_days*2-1)\n",
    "            except ValueError:\n",
    "                counter +=1\n",
    "                continue\n",
    "            event = cur_repo_data.index[cur_event]\n",
    "\n",
    "            before_vuln = event - gap_days\n",
    "            after_vuln = event + gap_days\n",
    "            res_event = cur_repo_data[before_vuln:event-1]\n",
    "            if not res_event[res_event[\"VulnEvent\"]>0].empty:\n",
    "                counter +=1\n",
    "                continue\n",
    "            benign_events.append(res_event.iloc[:,:-1].values)\n",
    "            found_event = True\n",
    "            \n",
    "            \n",
    "    return benign_events\n",
    "\n",
    "def create_all_events(cur_repo_data,gap_days):\n",
    "    all_events = []\n",
    "    labels = []\n",
    "    for i in range(gap_days,cur_repo_data.shape[0],1):\n",
    "            event = cur_repo_data.index[i]\n",
    "            before_vuln = event - gap_days\n",
    "            res_event = cur_repo_data[before_vuln:event-1]\n",
    "            all_events.append(res_event.iloc[:,:-1].values)\n",
    "            labels.append(res_event.iloc[:,-1].values)\n",
    "    return all_events,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd58e02-7df5-4656-9de5-5f4531ade86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1784 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Addition/subtraction of integers and integer-arrays with Timestamp is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# vulns = vulns.sort_index()\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vuln \u001b[38;5;129;01min\u001b[39;00m vulns:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# before,after = vuln - timedelta(days=gap_days),vuln + timedelta(days=gap_days)\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     before, after \u001b[38;5;241m=\u001b[39m \u001b[43mvuln\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgap_days\u001b[49m,vuln\u001b[38;5;241m+\u001b[39mgap_days\n\u001b[1;32m     82\u001b[0m     res \u001b[38;5;241m=\u001b[39m cur_repo_data[before:vuln\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aggr_option \u001b[38;5;241m==\u001b[39m Aggregate\u001b[38;5;241m.\u001b[39mafter_cve:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/tslibs/timestamps.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__sub__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/tslibs/timestamps.pyx:296\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps._Timestamp.__add__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Addition/subtraction of integers and integer-arrays with Timestamp is no longer supported.  Instead of adding/subtracting `n`, use `n * obj.freq`"
     ]
    }
   ],
   "source": [
    "repo_dirs = '../repo_gharchive_processed4'\n",
    "benign_all, vuln_all = [], []\n",
    "n_features = 0\n",
    "gap_days = 150\n",
    "\n",
    "nice_list= ['facebook_hhvm.csv',\n",
    "'ffmpeg_ffmpeg.csv',\n",
    "'flatpak_flatpak.csv',\n",
    "'freerdp_freerdp.csv',\n",
    "'git_git.csv',\n",
    "'gpac_gpac.csv',\n",
    "'imagemagick_imagemagick.csv',\n",
    "'kde_kdeconnect-kde.csv',\n",
    "'krb5_krb5.csv',\n",
    "'mantisbt_mantisbt.csv',\n",
    "'op-tee_optee_os.csv',\n",
    "'owncloud_core.csv',\n",
    "'php_php-src.csv',\n",
    "'revive-adserver_revive-adserver.csv',\n",
    "'rubygems_rubygems.csv',\n",
    "'the-tcpdump-group_tcpdump.csv']\n",
    "\n",
    "class Aggregate(Enum):\n",
    "    none = 1\n",
    "    before_cve = 2\n",
    "    after_cve = 3\n",
    "    \n",
    "aggr_option = Aggregate.after_cve\n",
    "\n",
    "for file in tqdm.tqdm(os.listdir(repo_dirs)[:]):\n",
    "    try:\n",
    "        try:\n",
    "            selected = 4\n",
    "            # if file != nice_list[selected]:\n",
    "            #          continue\n",
    "            cur_repo_data = pd.read_csv(repo_dirs + \"/\" + file,parse_dates=['created_at'],index_col='created_at')\n",
    "            \n",
    "            #    pass #all_events,labels = create_all_events(cur_repo_data,gap_days)\n",
    "                #correct_labels = [label[-1] for label in labels]\n",
    "            # if cur_repo_data[cur_repo_data[\"VulnEvent\"] > 0].values.shape[0]<5: \n",
    "            #     continue\n",
    "                \n",
    "            cur_repo_data = cur_repo_data[cur_repo_data.index.notnull()]\n",
    "            cur_repo_data[\"additions\"]=(cur_repo_data[\"additions\"]-cur_repo_data[\"additions\"].mean())/cur_repo_data[\"additions\"].std()\n",
    "            cur_repo_data[\"deletions\"]=(cur_repo_data[\"deletions\"]-cur_repo_data[\"deletions\"].mean())/cur_repo_data[\"deletions\"].std()\n",
    "            \n",
    "            y = pd.get_dummies(cur_repo_data.index.day_of_week, prefix='day_of_week')\n",
    "            y.index = cur_repo_data.index\n",
    "            cur_repo_data = pd.concat([cur_repo_data,y],axis=1)\n",
    "            y = pd.get_dummies(cur_repo_data.index.hour, prefix='hour')\n",
    "            y.index = cur_repo_data.index\n",
    "            cur_repo_data = pd.concat([cur_repo_data,y],axis=1)\n",
    "            \n",
    "            if aggr_option == Aggregate.before_cve:\n",
    "                cur_repo_data = cur_repo_data.resample('W-MON').sum()\n",
    "            if aggr_option != Aggregate.after_cve:\n",
    "                cur_repo_data = cur_repo_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        except pd.errors.EmptyDataError:\n",
    "            #print(file)\n",
    "            continue\n",
    "        if cur_repo_data.shape[0]<100:\n",
    "            continue\n",
    "        cols_at_end = ['VulnEvent']\n",
    "        cur_repo_data = cur_repo_data[[c for c in cur_repo_data if c not in cols_at_end]\n",
    "                                + [c for c in cols_at_end if c in cur_repo_data]]\n",
    "        # vulns = cur_repo_data[cur_repo_data[\"VulnEvent\"] > 0]\n",
    "        \n",
    "        \n",
    "        # if file == nice_list[selected]:\n",
    "        #     all_events,labels = create_all_events(cur_repo_data,gap_days)\n",
    "        \n",
    "        \n",
    "        vulns = cur_repo_data.index[cur_repo_data['VulnEvent'] > 0].tolist()\n",
    "\n",
    "        # vulns = vulns.sort_index()\n",
    "        \n",
    "        for vuln in vulns:\n",
    "            # before,after = vuln - timedelta(days=gap_days),vuln + timedelta(days=gap_days)\n",
    "            before, after = vuln-gap_days,vuln+gap_days\n",
    "            res = cur_repo_data[before:vuln-1].iloc[:,:-1].values\n",
    "            if aggr_option == Aggregate.after_cve:\n",
    "                cur_repo_data = cur_repo_data.resample('W-MON').sum()\n",
    "            vuln_all.append(res)\n",
    "        break\n",
    "        num_of_events = 7*len(vulns)\n",
    "        benigns=find_benign_events(cur_repo_data,gap_days,num_of_events)\n",
    "\n",
    "        for res in benigns:\n",
    "            benign_all.append(res)\n",
    "\n",
    "        \"\"\"for vuln in vulns.index:\n",
    "            before_vuln = vuln - timedelta(days=gap_days)\n",
    "            after_vuln = vuln + timedelta(days=gap_days)\n",
    "            # draw_timeline(file.split(\".csv\")[0],list(vulns.index),cur_data.index[0],cur_data.index[-1])\n",
    "            cur_data = cur_repo_data[before_vuln:after_vuln]\n",
    "\n",
    "\n",
    "            #cur_train_x, cur_train_y = split_sequence(cur_data.values, n_steps)\n",
    "\n",
    "            # if len(cur_train_x) == 0:\n",
    "            #     continue\n",
    "\n",
    "            all_train_x.append(cur_data.values)\n",
    "            all_train_y.append([1])\n",
    "\n",
    "        for benign in find_benign_events(cur_repo_data,gap_days,num_of_events):\n",
    "            print(benign.shape)\n",
    "            all_train_x.append(benign)\n",
    "            all_train_y.append([0])\"\"\"\n",
    "        #print(len(all_train_x),len(all_train_y))\n",
    "    except KeyError as e:\n",
    "        #print(file)\n",
    "        continue\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "        \n",
    "\n",
    "# all_train_x = np.array(all_train_x)\n",
    "# all_train_y = np.array(all_train_y)\n",
    "# print(all_train_x.shape,all_train_y.shape)\n",
    "# np.save('x.npy', all_train_x, allow_pickle=True)\n",
    "# np.save('y.npy', all_train_y, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b88a7485-9d0e-4bb7-a0c7-d4af62ae59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")\n",
    "\n",
    "max_vals = max(Counter([v.shape for v in vuln_all]))\n",
    "vuln_all = [v for v in vuln_all if v.shape == max_vals]\n",
    "max_vals = max(Counter([v.shape for v in benign_all]))\n",
    "benign_all = [v for v in benign_all if v.shape == max_vals]\n",
    "\n",
    "vuln_all =np.nan_to_num(np.array(vuln_all))\n",
    "benign_all = np.nan_to_num(np.array(benign_all)) \n",
    "\n",
    "\n",
    "np.save('vuln_week_150back_7_1.npy', np.array(vuln_all))    # .npy extension is added if not given\n",
    "np.save('benign_week_150back_7_1.npy', np.array(benign_all))    # .npy extension is added if not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "74277fe7-2307-4fdf-a4eb-ff3e0766cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vuln_all = np.load(\"vuln_week_150back_7_1.npy\")\n",
    "benign_all = np.load(\"benign_week_150back_7_1.npy\")\n",
    "def normalize(time_series_feature):\n",
    "    if time_series_feature.max()-time_series_feature.min() == 0:\n",
    "        return time_series_feature\n",
    "    return (time_series_feature-time_series_feature.min())/(time_series_feature.max()-time_series_feature.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ffd470e-d3a6-4b53-9472-efec6281c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_train_x = np.concatenate([vuln_all,benign_all])\n",
    "all_train_y = np.concatenate([np.ones(vuln_all.shape[0]),np.zeros(benign_all.shape[0])])\n",
    "all_train_x.shape,all_train_y.shape\n",
    "\n",
    "NORMALIZE = False\n",
    "\n",
    "if NORMALIZE:\n",
    "    all_train_x= normalize(all_train_x)\n",
    "    vuln_all2 = normalize(vuln_all)\n",
    "    benign_all2 = normalize(benign_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c122ed-d7b0-4a07-b87a-54b9c004e398",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12041, 149, 54) (149, 54)\n",
      "(12041,) ()\n",
      "Epoch 1/300\n",
      "283/283 [==============================] - 8s 25ms/step - loss: 1.1110 - accuracy: 0.6913 - val_loss: 0.5278 - val_accuracy: 0.7818\n",
      "Epoch 2/300\n",
      "283/283 [==============================] - 8s 30ms/step - loss: 0.5960 - accuracy: 0.7779 - val_loss: 0.5089 - val_accuracy: 0.7705\n",
      "Epoch 3/300\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.5343 - accuracy: 0.7956 - val_loss: 0.4536 - val_accuracy: 0.8107\n",
      "Epoch 4/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.4777 - accuracy: 0.8192 - val_loss: 0.4366 - val_accuracy: 0.8256\n",
      "Epoch 5/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.4617 - accuracy: 0.8454 - val_loss: 0.3809 - val_accuracy: 0.8525\n",
      "Epoch 6/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.4095 - accuracy: 0.8559 - val_loss: 0.3778 - val_accuracy: 0.8582\n",
      "Epoch 7/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.3962 - accuracy: 0.8639 - val_loss: 0.3850 - val_accuracy: 0.8509\n",
      "Epoch 8/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.3698 - accuracy: 0.8663 - val_loss: 0.3623 - val_accuracy: 0.8658\n",
      "Epoch 9/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.3633 - accuracy: 0.8710 - val_loss: 0.3631 - val_accuracy: 0.8592\n",
      "Epoch 10/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3641 - accuracy: 0.8739 - val_loss: 0.3639 - val_accuracy: 0.8572\n",
      "Epoch 11/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3543 - accuracy: 0.8752 - val_loss: 0.3547 - val_accuracy: 0.8575\n",
      "Epoch 12/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3513 - accuracy: 0.8769 - val_loss: 0.3582 - val_accuracy: 0.8635\n",
      "Epoch 13/300\n",
      "283/283 [==============================] - 12s 42ms/step - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.3450 - val_accuracy: 0.8622\n",
      "Epoch 14/300\n",
      "283/283 [==============================] - 12s 41ms/step - loss: 0.3509 - accuracy: 0.8807 - val_loss: 0.3520 - val_accuracy: 0.8632\n",
      "Epoch 15/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.3359 - accuracy: 0.8810 - val_loss: 0.3454 - val_accuracy: 0.8678\n",
      "Epoch 16/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.3281 - accuracy: 0.8826 - val_loss: 0.3314 - val_accuracy: 0.8765\n",
      "Epoch 17/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.3434 - accuracy: 0.8766 - val_loss: 0.3985 - val_accuracy: 0.8366\n",
      "Epoch 18/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.3423 - accuracy: 0.8766 - val_loss: 0.3482 - val_accuracy: 0.8589\n",
      "Epoch 19/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3212 - accuracy: 0.8866 - val_loss: 0.3318 - val_accuracy: 0.8715\n",
      "Epoch 20/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3171 - accuracy: 0.8850 - val_loss: 0.3322 - val_accuracy: 0.8711\n",
      "Epoch 21/300\n",
      "283/283 [==============================] - 11s 41ms/step - loss: 0.3192 - accuracy: 0.8889 - val_loss: 0.3413 - val_accuracy: 0.8688\n",
      "Epoch 22/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.3102 - accuracy: 0.8928 - val_loss: 0.3328 - val_accuracy: 0.8811\n",
      "Epoch 23/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.3146 - accuracy: 0.8921 - val_loss: 0.3463 - val_accuracy: 0.8811\n",
      "Epoch 24/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3683 - accuracy: 0.8847 - val_loss: 0.3466 - val_accuracy: 0.8725\n",
      "Epoch 25/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3136 - accuracy: 0.8896 - val_loss: 0.3315 - val_accuracy: 0.8838\n",
      "Epoch 26/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.3169 - accuracy: 0.8887 - val_loss: 0.3333 - val_accuracy: 0.8784\n",
      "Epoch 27/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3144 - accuracy: 0.8908 - val_loss: 0.3117 - val_accuracy: 0.8884\n",
      "Epoch 28/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3221 - accuracy: 0.8910 - val_loss: 0.3239 - val_accuracy: 0.8798\n",
      "Epoch 29/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3061 - accuracy: 0.8946 - val_loss: 0.3108 - val_accuracy: 0.8798\n",
      "Epoch 30/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3061 - accuracy: 0.8939 - val_loss: 0.3279 - val_accuracy: 0.8794\n",
      "Epoch 31/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.3031 - accuracy: 0.8929 - val_loss: 0.3233 - val_accuracy: 0.8858\n",
      "Epoch 32/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.3082 - accuracy: 0.8957 - val_loss: 0.3526 - val_accuracy: 0.8715\n",
      "Epoch 33/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3050 - accuracy: 0.8950 - val_loss: 0.3315 - val_accuracy: 0.8658\n",
      "Epoch 34/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3038 - accuracy: 0.8939 - val_loss: 0.3374 - val_accuracy: 0.8784\n",
      "Epoch 35/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3069 - accuracy: 0.8952 - val_loss: 0.3224 - val_accuracy: 0.8794\n",
      "Epoch 36/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.2961 - accuracy: 0.8961 - val_loss: 0.3259 - val_accuracy: 0.8794\n",
      "Epoch 37/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.2934 - accuracy: 0.8980 - val_loss: 0.3165 - val_accuracy: 0.8841\n",
      "Epoch 38/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3019 - accuracy: 0.8967 - val_loss: 0.3201 - val_accuracy: 0.8877\n",
      "Epoch 39/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3046 - accuracy: 0.8928 - val_loss: 0.3391 - val_accuracy: 0.8721\n",
      "Epoch 40/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.3055 - accuracy: 0.8961 - val_loss: 0.3293 - val_accuracy: 0.8844\n",
      "Epoch 41/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2945 - accuracy: 0.9013 - val_loss: 0.3031 - val_accuracy: 0.8937\n",
      "Epoch 42/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.2908 - accuracy: 0.9010 - val_loss: 0.3226 - val_accuracy: 0.8838\n",
      "Epoch 43/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2941 - accuracy: 0.8966 - val_loss: 0.3071 - val_accuracy: 0.8904\n",
      "Epoch 44/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2946 - accuracy: 0.8975 - val_loss: 0.3319 - val_accuracy: 0.8861\n",
      "Epoch 45/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2915 - accuracy: 0.9049 - val_loss: 0.3184 - val_accuracy: 0.8877\n",
      "Epoch 46/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2941 - accuracy: 0.9019 - val_loss: 0.3347 - val_accuracy: 0.8801\n",
      "Epoch 47/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2892 - accuracy: 0.9013 - val_loss: 0.3283 - val_accuracy: 0.8831\n",
      "Epoch 48/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2911 - accuracy: 0.9009 - val_loss: 0.3059 - val_accuracy: 0.8891\n",
      "Epoch 49/300\n",
      "283/283 [==============================] - 10s 37ms/step - loss: 0.2937 - accuracy: 0.9018 - val_loss: 0.3029 - val_accuracy: 0.8897\n",
      "Epoch 50/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2940 - accuracy: 0.9011 - val_loss: 0.3086 - val_accuracy: 0.8881\n",
      "Epoch 51/300\n",
      "283/283 [==============================] - 11s 37ms/step - loss: 0.2922 - accuracy: 0.9011 - val_loss: 0.3069 - val_accuracy: 0.8917\n",
      "Epoch 52/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2860 - accuracy: 0.9049 - val_loss: 0.3215 - val_accuracy: 0.8897\n",
      "Epoch 53/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2954 - accuracy: 0.9053 - val_loss: 0.3175 - val_accuracy: 0.8897\n",
      "Epoch 54/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2780 - accuracy: 0.9080 - val_loss: 0.3228 - val_accuracy: 0.8881\n",
      "Epoch 55/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2824 - accuracy: 0.9047 - val_loss: 0.3304 - val_accuracy: 0.8818\n",
      "Epoch 56/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2769 - accuracy: 0.9054 - val_loss: 0.3276 - val_accuracy: 0.8851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2790 - accuracy: 0.9075 - val_loss: 0.3204 - val_accuracy: 0.8871\n",
      "Epoch 58/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2852 - accuracy: 0.9061 - val_loss: 0.3475 - val_accuracy: 0.8728\n",
      "Epoch 59/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2922 - accuracy: 0.9016 - val_loss: 0.3028 - val_accuracy: 0.8921\n",
      "Epoch 60/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2856 - accuracy: 0.9050 - val_loss: 0.3397 - val_accuracy: 0.8804\n",
      "Epoch 61/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2846 - accuracy: 0.9051 - val_loss: 0.3246 - val_accuracy: 0.8894\n",
      "Epoch 62/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2760 - accuracy: 0.9096 - val_loss: 0.3120 - val_accuracy: 0.8934\n",
      "Epoch 63/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2702 - accuracy: 0.9114 - val_loss: 0.3094 - val_accuracy: 0.8917\n",
      "Epoch 64/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2790 - accuracy: 0.9076 - val_loss: 0.3072 - val_accuracy: 0.8894\n",
      "Epoch 65/300\n",
      "283/283 [==============================] - 13s 45ms/step - loss: 0.2788 - accuracy: 0.9075 - val_loss: 0.3627 - val_accuracy: 0.8379\n",
      "Epoch 66/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2905 - accuracy: 0.8996 - val_loss: 0.3304 - val_accuracy: 0.8884\n",
      "Epoch 67/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2825 - accuracy: 0.9075 - val_loss: 0.3117 - val_accuracy: 0.8934\n",
      "Epoch 68/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2746 - accuracy: 0.9087 - val_loss: 0.3128 - val_accuracy: 0.8934\n",
      "Epoch 69/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2908 - accuracy: 0.9012 - val_loss: 0.3323 - val_accuracy: 0.8708\n",
      "Epoch 70/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2849 - accuracy: 0.9051 - val_loss: 0.3243 - val_accuracy: 0.8758\n",
      "Epoch 71/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2761 - accuracy: 0.9052 - val_loss: 0.3185 - val_accuracy: 0.8901\n",
      "Epoch 72/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2705 - accuracy: 0.9115 - val_loss: 0.3203 - val_accuracy: 0.8907\n",
      "Epoch 73/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2770 - accuracy: 0.9081 - val_loss: 0.3126 - val_accuracy: 0.8934\n",
      "Epoch 74/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2823 - accuracy: 0.9068 - val_loss: 0.3071 - val_accuracy: 0.8941\n",
      "Epoch 75/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2704 - accuracy: 0.9083 - val_loss: 0.3118 - val_accuracy: 0.8894\n",
      "Epoch 76/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2676 - accuracy: 0.9138 - val_loss: 0.3056 - val_accuracy: 0.8927\n",
      "Epoch 77/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2738 - accuracy: 0.9096 - val_loss: 0.3108 - val_accuracy: 0.8934\n",
      "Epoch 78/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2694 - accuracy: 0.9111 - val_loss: 0.3215 - val_accuracy: 0.8891\n",
      "Epoch 79/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2681 - accuracy: 0.9130 - val_loss: 0.3212 - val_accuracy: 0.8934\n",
      "Epoch 80/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2698 - accuracy: 0.9153 - val_loss: 0.3037 - val_accuracy: 0.8990\n",
      "Epoch 81/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2643 - accuracy: 0.9158 - val_loss: 0.3026 - val_accuracy: 0.8914\n",
      "Epoch 82/300\n",
      "283/283 [==============================] - 11s 38ms/step - loss: 0.2699 - accuracy: 0.9125 - val_loss: 0.3044 - val_accuracy: 0.8931\n",
      "Epoch 83/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2788 - accuracy: 0.9092 - val_loss: 0.3290 - val_accuracy: 0.8788\n",
      "Epoch 84/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2713 - accuracy: 0.9111 - val_loss: 0.3198 - val_accuracy: 0.8914\n",
      "Epoch 85/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2741 - accuracy: 0.9118 - val_loss: 0.2924 - val_accuracy: 0.9030\n",
      "Epoch 86/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2640 - accuracy: 0.9125 - val_loss: 0.3060 - val_accuracy: 0.8994\n",
      "Epoch 87/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2769 - accuracy: 0.9130 - val_loss: 0.3066 - val_accuracy: 0.8980\n",
      "Epoch 88/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2832 - accuracy: 0.9142 - val_loss: 0.3076 - val_accuracy: 0.8941\n",
      "Epoch 89/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2758 - accuracy: 0.9123 - val_loss: 0.3117 - val_accuracy: 0.8951\n",
      "Epoch 90/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2692 - accuracy: 0.9157 - val_loss: 0.3156 - val_accuracy: 0.8957\n",
      "Epoch 91/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2686 - accuracy: 0.9171 - val_loss: 0.3235 - val_accuracy: 0.8941\n",
      "Epoch 92/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2704 - accuracy: 0.9154 - val_loss: 0.3327 - val_accuracy: 0.8884\n",
      "Epoch 93/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2741 - accuracy: 0.9143 - val_loss: 0.3140 - val_accuracy: 0.8977\n",
      "Epoch 94/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2754 - accuracy: 0.9127 - val_loss: 0.3091 - val_accuracy: 0.8994\n",
      "Epoch 95/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2701 - accuracy: 0.9133 - val_loss: 0.3280 - val_accuracy: 0.8804\n",
      "Epoch 96/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2700 - accuracy: 0.9126 - val_loss: 0.3115 - val_accuracy: 0.8951\n",
      "Epoch 97/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2725 - accuracy: 0.9123 - val_loss: 0.3140 - val_accuracy: 0.8954\n",
      "Epoch 98/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2838 - accuracy: 0.9128 - val_loss: 0.3163 - val_accuracy: 0.8980\n",
      "Epoch 99/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2634 - accuracy: 0.9163 - val_loss: 0.3067 - val_accuracy: 0.8974\n",
      "Epoch 100/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2769 - accuracy: 0.9134 - val_loss: 0.3181 - val_accuracy: 0.8881\n",
      "Epoch 101/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2535 - accuracy: 0.9208 - val_loss: 0.3045 - val_accuracy: 0.9067\n",
      "Epoch 102/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2533 - accuracy: 0.9216 - val_loss: 0.2952 - val_accuracy: 0.9040\n",
      "Epoch 103/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2629 - accuracy: 0.9150 - val_loss: 0.3139 - val_accuracy: 0.8970\n",
      "Epoch 104/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2654 - accuracy: 0.9186 - val_loss: 0.3061 - val_accuracy: 0.8967\n",
      "Epoch 105/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2571 - accuracy: 0.9162 - val_loss: 0.3065 - val_accuracy: 0.8984\n",
      "Epoch 106/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2723 - accuracy: 0.9116 - val_loss: 0.3307 - val_accuracy: 0.8672\n",
      "Epoch 107/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2832 - accuracy: 0.9058 - val_loss: 0.3059 - val_accuracy: 0.8954\n",
      "Epoch 108/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2751 - accuracy: 0.9101 - val_loss: 0.3055 - val_accuracy: 0.8934\n",
      "Epoch 109/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2631 - accuracy: 0.9146 - val_loss: 0.3133 - val_accuracy: 0.8977\n",
      "Epoch 110/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2851 - accuracy: 0.9103 - val_loss: 0.3150 - val_accuracy: 0.8934\n",
      "Epoch 111/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2681 - accuracy: 0.9137 - val_loss: 0.3308 - val_accuracy: 0.8881\n",
      "Epoch 112/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2664 - accuracy: 0.9158 - val_loss: 0.3175 - val_accuracy: 0.8907\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2641 - accuracy: 0.9153 - val_loss: 0.3075 - val_accuracy: 0.8970\n",
      "Epoch 114/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2683 - accuracy: 0.9188 - val_loss: 0.3059 - val_accuracy: 0.8987\n",
      "Epoch 115/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2598 - accuracy: 0.9188 - val_loss: 0.3184 - val_accuracy: 0.8951\n",
      "Epoch 116/300\n",
      "283/283 [==============================] - 12s 41ms/step - loss: 0.2618 - accuracy: 0.9168 - val_loss: 0.3061 - val_accuracy: 0.8984\n",
      "Epoch 117/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2509 - accuracy: 0.9204 - val_loss: 0.3012 - val_accuracy: 0.8990\n",
      "Epoch 118/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2555 - accuracy: 0.9182 - val_loss: 0.3063 - val_accuracy: 0.8997\n",
      "Epoch 119/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2594 - accuracy: 0.9189 - val_loss: 0.3039 - val_accuracy: 0.9037\n",
      "Epoch 120/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2652 - accuracy: 0.9179 - val_loss: 0.3154 - val_accuracy: 0.8984\n",
      "Epoch 121/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2723 - accuracy: 0.9188 - val_loss: 0.2910 - val_accuracy: 0.9077\n",
      "Epoch 122/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2570 - accuracy: 0.9158 - val_loss: 0.3142 - val_accuracy: 0.8794\n",
      "Epoch 123/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2544 - accuracy: 0.9176 - val_loss: 0.3074 - val_accuracy: 0.8997\n",
      "Epoch 124/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2685 - accuracy: 0.9204 - val_loss: 0.3066 - val_accuracy: 0.9020\n",
      "Epoch 125/300\n",
      "283/283 [==============================] - 11s 41ms/step - loss: 0.2559 - accuracy: 0.9186 - val_loss: 0.2989 - val_accuracy: 0.8987\n",
      "Epoch 126/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2559 - accuracy: 0.9183 - val_loss: 0.3014 - val_accuracy: 0.9037\n",
      "Epoch 127/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2525 - accuracy: 0.9205 - val_loss: 0.3089 - val_accuracy: 0.8980\n",
      "Epoch 128/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2550 - accuracy: 0.9213 - val_loss: 0.3094 - val_accuracy: 0.8974\n",
      "Epoch 129/300\n",
      "283/283 [==============================] - 11s 40ms/step - loss: 0.2506 - accuracy: 0.9229 - val_loss: 0.3267 - val_accuracy: 0.8951\n",
      "Epoch 130/300\n",
      "283/283 [==============================] - 12s 41ms/step - loss: 0.2554 - accuracy: 0.9205 - val_loss: 0.2922 - val_accuracy: 0.9047\n",
      "Epoch 131/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2588 - accuracy: 0.9190 - val_loss: 0.3137 - val_accuracy: 0.8984\n",
      "Epoch 132/300\n",
      "283/283 [==============================] - 11s 39ms/step - loss: 0.2498 - accuracy: 0.9219 - val_loss: 0.3167 - val_accuracy: 0.8974\n",
      "Epoch 133/300\n",
      "283/283 [==============================] - 24s 84ms/step - loss: 0.2580 - accuracy: 0.9203 - val_loss: 0.3111 - val_accuracy: 0.8947\n",
      "Epoch 134/300\n",
      "283/283 [==============================] - 41s 146ms/step - loss: 0.2605 - accuracy: 0.9198 - val_loss: 0.3178 - val_accuracy: 0.8957\n",
      "Epoch 135/300\n",
      "283/283 [==============================] - 21s 74ms/step - loss: 0.2528 - accuracy: 0.9202 - val_loss: 0.3072 - val_accuracy: 0.8967\n",
      "Epoch 136/300\n",
      "283/283 [==============================] - 23s 83ms/step - loss: 0.2485 - accuracy: 0.9223 - val_loss: 0.3029 - val_accuracy: 0.9024\n",
      "Epoch 137/300\n",
      "283/283 [==============================] - 29s 104ms/step - loss: 0.2493 - accuracy: 0.9226 - val_loss: 0.3058 - val_accuracy: 0.9000\n",
      "Epoch 138/300\n",
      "283/283 [==============================] - 27s 96ms/step - loss: 0.2545 - accuracy: 0.9231 - val_loss: 0.3131 - val_accuracy: 0.9050\n",
      "Epoch 139/300\n",
      "283/283 [==============================] - 16s 57ms/step - loss: 0.2573 - accuracy: 0.9212 - val_loss: 0.3213 - val_accuracy: 0.8901\n",
      "Epoch 140/300\n",
      "283/283 [==============================] - 17s 59ms/step - loss: 0.2733 - accuracy: 0.9115 - val_loss: 0.3080 - val_accuracy: 0.8927\n",
      "Epoch 141/300\n",
      "283/283 [==============================] - 16s 57ms/step - loss: 0.2625 - accuracy: 0.9167 - val_loss: 0.3016 - val_accuracy: 0.8990\n",
      "Epoch 142/300\n",
      "283/283 [==============================] - 28s 99ms/step - loss: 0.2587 - accuracy: 0.9174 - val_loss: 0.3067 - val_accuracy: 0.8941\n",
      "Epoch 143/300\n",
      "283/283 [==============================] - 20s 72ms/step - loss: 0.2646 - accuracy: 0.9164 - val_loss: 0.3053 - val_accuracy: 0.8951\n",
      "Epoch 144/300\n",
      "283/283 [==============================] - 19s 68ms/step - loss: 0.2531 - accuracy: 0.9200 - val_loss: 0.3060 - val_accuracy: 0.8984\n",
      "Epoch 145/300\n",
      "283/283 [==============================] - 14s 51ms/step - loss: 0.2545 - accuracy: 0.9175 - val_loss: 0.2996 - val_accuracy: 0.8960\n",
      "Epoch 146/300\n",
      "283/283 [==============================] - 12s 43ms/step - loss: 0.2640 - accuracy: 0.9152 - val_loss: 0.3192 - val_accuracy: 0.8931\n",
      "Epoch 147/300\n",
      "283/283 [==============================] - 12s 43ms/step - loss: 0.2601 - accuracy: 0.9194 - val_loss: 0.3301 - val_accuracy: 0.8927\n",
      "Epoch 148/300\n",
      "283/283 [==============================] - 12s 44ms/step - loss: 0.2541 - accuracy: 0.9205 - val_loss: 0.3207 - val_accuracy: 0.8967\n",
      "Epoch 149/300\n",
      "283/283 [==============================] - 16s 58ms/step - loss: 0.2505 - accuracy: 0.9230 - val_loss: 0.3101 - val_accuracy: 0.9024\n",
      "Epoch 150/300\n",
      "283/283 [==============================] - 13s 45ms/step - loss: 0.2622 - accuracy: 0.9175 - val_loss: 0.3152 - val_accuracy: 0.8924\n",
      "Epoch 151/300\n",
      "283/283 [==============================] - 22s 76ms/step - loss: 0.2482 - accuracy: 0.9227 - val_loss: 0.3132 - val_accuracy: 0.8980\n",
      "Epoch 152/300\n",
      "283/283 [==============================] - 19s 69ms/step - loss: 0.2545 - accuracy: 0.9205 - val_loss: 0.3232 - val_accuracy: 0.9017\n",
      "Epoch 153/300\n",
      "283/283 [==============================] - 13s 45ms/step - loss: 0.2550 - accuracy: 0.9224 - val_loss: 0.3162 - val_accuracy: 0.8904\n",
      "Epoch 154/300\n",
      "283/283 [==============================] - 14s 50ms/step - loss: 0.2487 - accuracy: 0.9226 - val_loss: 0.3240 - val_accuracy: 0.8994\n",
      "Epoch 155/300\n",
      "283/283 [==============================] - 17s 59ms/step - loss: 0.2824 - accuracy: 0.9214 - val_loss: 0.3230 - val_accuracy: 0.8970\n",
      "Epoch 156/300\n",
      "283/283 [==============================] - 29s 103ms/step - loss: 0.2478 - accuracy: 0.9236 - val_loss: 0.3338 - val_accuracy: 0.8990\n",
      "Epoch 157/300\n",
      "283/283 [==============================] - 16s 57ms/step - loss: 0.2729 - accuracy: 0.9187 - val_loss: 0.3016 - val_accuracy: 0.9020\n",
      "Epoch 158/300\n",
      "283/283 [==============================] - 22s 79ms/step - loss: 0.2539 - accuracy: 0.9218 - val_loss: 0.3168 - val_accuracy: 0.8970\n",
      "Epoch 159/300\n",
      "283/283 [==============================] - 14s 50ms/step - loss: 0.2659 - accuracy: 0.9192 - val_loss: 0.3146 - val_accuracy: 0.8954\n",
      "Epoch 160/300\n",
      "283/283 [==============================] - 13s 46ms/step - loss: 0.2495 - accuracy: 0.9219 - val_loss: 0.3215 - val_accuracy: 0.9004\n",
      "Epoch 161/300\n",
      "283/283 [==============================] - 13s 46ms/step - loss: 0.2488 - accuracy: 0.9233 - val_loss: 0.3119 - val_accuracy: 0.9024\n",
      "Epoch 162/300\n",
      "283/283 [==============================] - 18s 62ms/step - loss: 0.2559 - accuracy: 0.9218 - val_loss: 0.3018 - val_accuracy: 0.9034\n",
      "Epoch 163/300\n",
      "283/283 [==============================] - 19s 66ms/step - loss: 0.2479 - accuracy: 0.9252 - val_loss: 0.3114 - val_accuracy: 0.8951\n",
      "Epoch 164/300\n",
      "283/283 [==============================] - 13s 47ms/step - loss: 0.2587 - accuracy: 0.9168 - val_loss: 0.3015 - val_accuracy: 0.9000\n",
      "Epoch 165/300\n",
      "283/283 [==============================] - 14s 48ms/step - loss: 0.2593 - accuracy: 0.9204 - val_loss: 0.3183 - val_accuracy: 0.8957\n",
      "Epoch 166/300\n",
      "283/283 [==============================] - 14s 49ms/step - loss: 0.2559 - accuracy: 0.9256 - val_loss: 0.3199 - val_accuracy: 0.8954\n",
      "Epoch 167/300\n",
      "283/283 [==============================] - 16s 55ms/step - loss: 0.2498 - accuracy: 0.9236 - val_loss: 0.3113 - val_accuracy: 0.8990\n",
      "Epoch 168/300\n",
      "283/283 [==============================] - 17s 61ms/step - loss: 0.2558 - accuracy: 0.9226 - val_loss: 0.2959 - val_accuracy: 0.9047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "283/283 [==============================] - 20s 72ms/step - loss: 0.2406 - accuracy: 0.9279 - val_loss: 0.3254 - val_accuracy: 0.8874\n",
      "Epoch 170/300\n",
      "283/283 [==============================] - 24s 86ms/step - loss: 0.2446 - accuracy: 0.9245 - val_loss: 0.3073 - val_accuracy: 0.8987\n",
      "Epoch 171/300\n",
      "283/283 [==============================] - 18s 65ms/step - loss: 0.2431 - accuracy: 0.9251 - val_loss: 0.3164 - val_accuracy: 0.8897\n",
      "Epoch 172/300\n",
      "283/283 [==============================] - 15s 54ms/step - loss: 0.2538 - accuracy: 0.9227 - val_loss: 0.3258 - val_accuracy: 0.8937\n",
      "Epoch 173/300\n",
      "283/283 [==============================] - 15s 55ms/step - loss: 0.2735 - accuracy: 0.9237 - val_loss: 0.3147 - val_accuracy: 0.8977\n",
      "Epoch 174/300\n",
      "283/283 [==============================] - 15s 54ms/step - loss: 0.2467 - accuracy: 0.9256 - val_loss: 0.2931 - val_accuracy: 0.9037\n",
      "Epoch 175/300\n",
      "283/283 [==============================] - 18s 64ms/step - loss: 0.2381 - accuracy: 0.9296 - val_loss: 0.3096 - val_accuracy: 0.9010\n",
      "Epoch 176/300\n",
      "283/283 [==============================] - 14s 48ms/step - loss: 0.2391 - accuracy: 0.9282 - val_loss: 0.3095 - val_accuracy: 0.8911\n",
      "Epoch 177/300\n",
      "283/283 [==============================] - 14s 49ms/step - loss: 0.2532 - accuracy: 0.9202 - val_loss: 0.3135 - val_accuracy: 0.8951\n",
      "Epoch 178/300\n",
      "283/283 [==============================] - 13s 47ms/step - loss: 0.2621 - accuracy: 0.9189 - val_loss: 0.3082 - val_accuracy: 0.8980\n",
      "Epoch 179/300\n",
      "283/283 [==============================] - 16s 57ms/step - loss: 0.2595 - accuracy: 0.9213 - val_loss: 0.2992 - val_accuracy: 0.9044\n",
      "Epoch 180/300\n",
      "283/283 [==============================] - 16s 57ms/step - loss: 0.2408 - accuracy: 0.9261 - val_loss: 0.3103 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "283/283 [==============================] - 27s 96ms/step - loss: 0.2454 - accuracy: 0.9240 - val_loss: 0.3042 - val_accuracy: 0.8977\n",
      "Epoch 182/300\n",
      "283/283 [==============================] - 36s 128ms/step - loss: 0.2650 - accuracy: 0.9243 - val_loss: 0.2933 - val_accuracy: 0.9014\n",
      "Epoch 183/300\n",
      "283/283 [==============================] - 25s 87ms/step - loss: 0.2499 - accuracy: 0.9243 - val_loss: 0.3000 - val_accuracy: 0.9010\n",
      "Epoch 184/300\n",
      "283/283 [==============================] - 162s 573ms/step - loss: 0.2780 - accuracy: 0.9256 - val_loss: 0.2939 - val_accuracy: 0.9037\n",
      "Epoch 185/300\n",
      "283/283 [==============================] - 70s 250ms/step - loss: 0.2511 - accuracy: 0.9261 - val_loss: 0.3063 - val_accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9270"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "print(all_train_x.shape, all_train_x[0].shape)\n",
    "print(all_train_y.shape, all_train_y[0].shape)\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_train_x,all_train_y,shuffle=True)\n",
    "\n",
    "\n",
    "RESAMPLE = False\n",
    "if RESAMPLE:\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    ros.fit_resample(X_train[:,:,0], y_train)\n",
    "    X_train = X_train[ros.sample_indices_]\n",
    "    y_train = y_train[ros.sample_indices_]\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "reshaped_train,reshaped_test = X_train.reshape(X_train.shape[0],-1), X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max',patience=30)\n",
    "\n",
    "history = model.fit(X_train, y_train, verbose=1,epochs=300, batch_size=32,validation_data=(X_test,y_test),callbacks=[])\n",
    "\n",
    "# print(model.evaluate(X_test.reshape(X_test.shape[0],-1), y_test, verbose=0))\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'val'], loc='upper left')\n",
    "pyplot.show()\n",
    "\n",
    "# model.fit(benign_all2, benign_all2, epochs=100)\n",
    "          \n",
    "\"\"\"\n",
    "threshold = find_threshold(model, benign_all2)\n",
    "print(f\"Threshold: {threshold}\")\n",
    "# Threshold: 0.01001314025746261\n",
    "predictions = get_predictions(model, vuln_all2, threshold)\n",
    "accuracy_score(predictions, [0]*len(vuln_all2))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = np.array(all_events)\n",
    "all_events.shape\n",
    "df = DataFrame(model.predict(all_events),columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"models/150back2000epochs_84valaccuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred2'] = df['pred'].apply(lambda x: 0.0 if x < 0.3 else 1.0)\n",
    "df['real']=[int(label[-1]>0) for label in labels]\n",
    "df[['pred','real']].iloc[:].plot()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4795ef-cd7f-4b7c-a986-e275c8f89107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "def find_best_f1(X_test,y_test,model):\n",
    "    max_f1 = 0\n",
    "    thresh = 0\n",
    "    best_y = 0\n",
    "    pred = model.predict(X_test)\n",
    "    for i in range(100):\n",
    "        y_predict = (pred.reshape(-1)>i/100).astype(int)\n",
    "        precision, recall, fscore, support = score(y_test,y_predict ,zero_division=0)\n",
    "        cur_f1 = fscore[1]\n",
    "        print(i,cur_f1)\n",
    "        if cur_f1 > max_f1:\n",
    "            max_f1 = cur_f1\n",
    "            best_y = y_predict\n",
    "            thresh = i / 100\n",
    "    return max_f1,thresh, best_y\n",
    "\n",
    "\n",
    "f1,thresh,best_y = find_best_f1(X_test,y_test,model)\n",
    "print(f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739433b9-0d80-4d90-9605-b8ee65182f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_test.reshape(X_test.shape[0],-1), y_test, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033be7a-fe26-422e-b439-3112433e007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unshaped = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "a = model.predict(unshaped)\n",
    "from pandas import DataFrame\n",
    "DataFrame(a).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5969fe-0538-497c-becd-dc6271e560e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(unshaped)\n",
    "res['predict']=a\n",
    "res['real']=y_test\n",
    "res2=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9099a9-68c9-478f-a9e8-0740d4956104",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2=res\n",
    "res2['predict']=res2['predict'].apply(lambda x: 0.0 if x<0.5 else 1.0)\n",
    "res2[res['predict']!=res['real']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddd4e1-1292-445e-8766-3b9a61be842d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c3d80-5789-484a-914b-285383e5e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(models)\n",
    "model.save(f'models/serial_1_4_f1_{f1}.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9ffae-b58d-4f31-89cf-b64d3081fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "nb_epoch = 10\n",
    "batch_size = 64\n",
    "input_dim = benign_all2.shape[1] #num of columns, 30\n",
    "encoding_dim = 14\n",
    "hidden_dim_1 = int(encoding_dim / 2) #\n",
    "hidden_dim_2=4  \n",
    "learning_rate = 1e-7\n",
    "\n",
    "#input Layer\n",
    "input_layer = tf.keras.layers.Input(shape=(input_dim, ))\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(encoding_dim, activation=\"tanh\",                                activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "encoder=tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n",
    "# Decoder\n",
    "decoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "decoder=tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(input_dim, activation='tanh')(decoder)\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "#autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "history = autoencoder.fit(benign_all2, benign_all2,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(vuln_all2, vuln_all2),\n",
    "                    verbose=1,\n",
    "                    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a2e3a-e47f-46b9-afdd-5a46bbb6bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "vuln_all2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e747084-20fc-4bac-b5a5-7daedb42468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mall = np.concatenate([benign_all2,vuln_all2]) # .shape ,benign_all2.shape,vuln_all2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facda764-8143-4d5a-9527-d455b5a9abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold_fixed = 0.1\n",
    "check = vuln_all2\n",
    "#mall = check\n",
    "test_x_predictions1 = autoencoder.predict(vuln_all2)\n",
    "# test_x_predictions2 = autoencoder.predict(mall[int(mall.shape[0]/2):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb9907-b298-4c67-8a0d-9ab788cc9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(mall - test_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': len(benign_all2)*[0]+len(vuln_all2)*[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7a381-2b2f-450c-9c7f-e6fd8967cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = error_df.groupby('True_class')\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(0.4, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "# plt.ylim([0,1])\n",
    "plt.title(\"Reconstruction error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9da97c-ecc4-40bc-9ad3-8a3fac96518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions, [1]*len(vuln_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85653fc6-fb01-40d9-ba4c-a270c6faba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = autoencoder.predict(test_data)\n",
    "mse = np.mean(np.power(test_data - test_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_labels})\n",
    "Plotting the test data points and their respective reconstruction error sets a threshold value to visualize if the threshold value needs to be adjusted.\n",
    "threshold_fixed = 50\n",
    "groups = error_df.groupby('True_class')\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold_fixed, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show();\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "def find_threshold(model, x_train_scaled):\n",
    "    reconstructions = model.predict(x_train_scaled)\n",
    "    # provides losses of individual instances\n",
    "    reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
    "    # threshold for anomaly scores\n",
    "    threshold = np.mean(reconstruction_errors.numpy()) \\\n",
    "      + np.std(reconstruction_errors.numpy())\n",
    "    return threshold\n",
    "\n",
    "def get_predictions(model, x_test_scaled, threshold):\n",
    "    predictions = model.predict(x_test_scaled)\n",
    "    # provides losses of individual instances\n",
    "    errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
    "    # 0 = anomaly, 1 = normal\n",
    "    anomaly_mask = pd.Series(errors) > threshold\n",
    "    preds = anomaly_mask.map(lambda x: 0.0 if x == True else 1.0)\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095a8e1-974e-4a46-b8de-7fb8ab6ecbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(model, vuln_all2, threshold-0.000011)\n",
    "accuracy_score(predictions, [0]*len(vuln_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecb936-9f36-4334-b1ec-0c6daadf8f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796045b-136d-49e3-9bbd-0a905994b827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0e935-6a80-45f9-a38c-7fb1eb0e5a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29717280-5df8-4284-846a-26123bdaef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    print(i,np.isnan(all_train_x[:,:,i]).any())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6881ef-e152-4388-9b02-b5813c26c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_x = all_train_x[:,:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15b0b8-4308-4f5d-bc0f-443a5f6544f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(100, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100,validation_data=(X_test,y_test),verbose=1)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"model = Sequential()\n",
    "\n",
    "model.add(LSTM(100, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5,validation_data=(X_test,y_test),verbose=2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"model = Sequential()\n",
    "model.add(Dense(50, input_shape=[all_train_x.shape[1]], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"model = Sequential()\n",
    "model.add(Dense(150,input_shape=[benign_all2.shape[1]], activation='linear')) \n",
    "model.add(Dense(75, activation=\"linear\"))\n",
    "model.add(Dense(10, activation=\"linear\"))\n",
    "model.add(Dense(75, activation=\"linear\"))\n",
    "model.add(Dense(benign_all2.shape[1], activation=\"linear\"))\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
